{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b3dd4f-6c86-456a-b7c2-a73985a91ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GEOG696C Spatiotemporal Data Analytics: Term Project\n",
    "## extractPixelFIATimeSeries.ipynb\n",
    "This script extracts time series of fractional inundated area (FIA) per pixel from the Giezendanner et al. (2023) dataset of historical flooding. I create time series of weekly FIA for each 500 m pixel, before aggregating to monthly, seasonal and annual time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b5fc22-8f3a-4e36-99b0-8c2240b04ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "# import rioxarray\n",
    "# import xarray\n",
    "# from shapely.geometry import Polygon\n",
    "# from shapely.geometry import Point\n",
    "# import matplotlib.pyplot as plt\n",
    "# from itertools import chain\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e090b766-cc0a-4cdc-8361-29e63c1f419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root path\n",
    "# rootPath = Path('/media/mule/Projects/NASA/NIP/Data')\n",
    "rootPath = Path('C:/Users/alexsaunders/Documents/01_uoa/01_study/2023/geog696c/project/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd526d-cb9f-40b6-86b1-e2a4b2d2e2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) Get the rasters with the FIA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dad65004-9a11-4809-abab-b084c4b9039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataPath = rootPath/'Models/DeepLearning/Inference/CrossValidation/Archive/Historical/Ensemble'\n",
    "dataPath = Path('C:/Users/alexsaunders/Documents/01_uoa/02_ra/01_projects/01_nip/02_hysteresis/inTmp') # local copy\n",
    "dataFiles = [file for file in list(dataPath.iterdir()) if file.suffix=='.tiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5033b848-e24a-4584-8595-b6badc2c4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985\n"
     ]
    }
   ],
   "source": [
    "print(len(dataFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f31449be-f2b9-4de8-8f9e-b4c1569b3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFiles.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46722c95-ddd9-44ea-9597-e99661db94a3",
   "metadata": {},
   "source": [
    "## 2) Get the dimensions of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c308ed9-b1b3-4e08-b401-860ecee2fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1346, 1040) 1399840\n"
     ]
    }
   ],
   "source": [
    "# Open a single raster and get the spatial dimensions\n",
    "file = dataFiles[0]\n",
    "raster = rio.open(file)\n",
    "rasterData = raster.read(1)\n",
    "print(rasterData.shape, rasterData.shape[0]*rasterData.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cbf57ed-c0f8-411b-8f96-9db97f045a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dimensions we want\n",
    "nrows = rasterData.shape[0]\n",
    "ncols = rasterData.shape[1]\n",
    "ntime = len(dataFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d526bfb-3d40-4d95-8d62-84783b535258",
   "metadata": {},
   "source": [
    "## 3) Get the raster pixel data for all dates to create time series for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd83ca11-140a-4069-b284-0c595d839ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dates of all the raster files\n",
    "imageDates=[]\n",
    "# Loop through the tif files\n",
    "for f, file in enumerate(dataFiles):\n",
    "    # Get the data of the image\n",
    "    imageDate = datetime.fromtimestamp(int(file.stem[:-3])).strftime('%Y%m%d')\n",
    "    imageDates.append(imageDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfae7d44-2cbd-4db9-8b90-81259455d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty array for storing the values\n",
    "rasterDataAllDates = np.zeros([nrows, ncols, ntime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e7339ee-4bc8-4290-94a1-2edede73a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files and for each one, record the pixel value into an array with values for the same pixel from all other dates\n",
    "# Loop through the tif files\n",
    "for f, file in enumerate(dataFiles):\n",
    "    # Open and get raster values\n",
    "    with rio.open(file) as raster:\n",
    "        # Assign raster values to array\n",
    "        rasterDataAllDates[:,:,f]=raster.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb6403b5-a019-4d5c-8d98-4b3a667be317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1399840, 985)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the dimensions to 2D i.e. location and time\n",
    "rasterData2D = rasterDataAllDates.reshape([nrows*ncols, ntime])\n",
    "print(rasterData2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f729eec-8ccf-4316-9f3f-b7584af5dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for saving pixel FIA outputs\n",
    "outPath=rootPath/'pixelFIA'\n",
    "outPath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e3b230b-7584-44a2-9028-c4522fb08a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out to a csv file\n",
    "rasterData2D.tofile(outPath/'pixelFIAAllDates.txt', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "68fa0c36-1d99-4ad8-8564-3359bcbf04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nodata value of -9999 with np.nan to see if it reduces size\n",
    "rasterData2Dnan = rasterData2D.copy()\n",
    "rasterData2Dnan[rasterData2Dnan == -9999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deb729d5-3a87-43b0-915f-7cdc1fc701d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterData2Dnan.tofile(outPath/'pixelFIAAllDatesNan.txt', sep = '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5d003-635a-482c-a633-cf52619b571f",
   "metadata": {},
   "source": [
    "### Export as multiple blocks to csv\n",
    "Note: file format is rows = locations, columns = timestamps with dates given by imageDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e8f85ecb-3f92-4347-a5d6-cb783b52cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the array to dataframe for exporting as csv\n",
    "rasterDataDF = pd.DataFrame(rasterData2Dnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e6f9e4af-44b4-4263-b74c-2cd4cd8b88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for saving pixel FIA outputs\n",
    "outPath=rootPath/'pixelFIA/raw'\n",
    "outPath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3bf9781d-303d-40fe-8a53-7b4820476b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>975</th>\n",
       "      <th>976</th>\n",
       "      <th>977</th>\n",
       "      <th>978</th>\n",
       "      <th>979</th>\n",
       "      <th>980</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>984</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399835</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399836</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399837</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399838</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399839</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1399840 rows × 985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9    ...  975  976  977  \\\n",
       "0        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "2        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1399835  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1399836  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1399837  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1399838  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1399839  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "         978  979  980  981  982  983  984  \n",
       "0        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  \n",
       "1399835  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1399836  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1399837  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1399838  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1399839  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[1399840 rows x 985 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasterDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9051dc3-38e9-4237-9602-bae409422000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100000\n",
      "100000 200000\n"
     ]
    }
   ],
   "source": [
    "# Export in csvs of 100,000 rows at a time\n",
    "blockSize = 100000\n",
    "\n",
    "# Calculate the number of blocks\n",
    "nBlocks = (len(rasterDataDF) + blockSize - 1) // blockSize\n",
    "\n",
    "for b, start in enumerate(range(0, len(rasterDataDF), blockSize)):\n",
    "    end = start + blockSize\n",
    "    if end > len(rasterDataDF):\n",
    "        end = len(rasterDataDF)\n",
    "    print(start, end)\n",
    "    block = rasterDataDF.iloc[start:end]\n",
    "    block.to_csv(outPath/(str(b)+'.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae1576-7f57-496c-b186-77895bd314db",
   "metadata": {},
   "source": [
    "## 4) Extract pixel FIA by aggregation time unit - month, season, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a8b47d9-4400-4406-9ab1-6da0322d79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep a dataframe of dates and flags for aggregating by time unit\n",
    "datesDF = pd.DataFrame(data=[imageDates], index=['date']).T \n",
    "datesDF['datetime'] = pd.to_datetime(datesDF.date)\n",
    "datesDF['year']=[item.year for item in datesDF.datetime]\n",
    "datesDF['month']=[item.month for item in datesDF.datetime]\n",
    "datesDF['yearID']=datesDF.year - datesDF.year.min()\n",
    "datesDF['monthID']=datesDF.yearID*12 +  datesDF.month\n",
    "\n",
    "months=[5,6,7,8,9,10]\n",
    "datesDF.loc[datesDF.month.isin(months),'monsoon']=1\n",
    "datesDF['monsoonID']=datesDF.yearID*datesDF.monsoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c17246a3-6c88-4f0c-bbfe-588a9c469e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use idx to map back to time dimension of the array containing the pixel FIA values\n",
    "datesDF['idx']=datesDF.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cea81797-d59b-45e8-9f33-9f4bc77cf479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>yearID</th>\n",
       "      <th>monthID</th>\n",
       "      <th>monsoon</th>\n",
       "      <th>monsoonID</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010909</td>\n",
       "      <td>2001-09-09</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010917</td>\n",
       "      <td>2001-09-17</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010925</td>\n",
       "      <td>2001-09-25</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20011003</td>\n",
       "      <td>2001-10-03</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20011011</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>20010731</td>\n",
       "      <td>2001-07-31</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>20010808</td>\n",
       "      <td>2001-08-08</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>20010816</td>\n",
       "      <td>2001-08-16</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>20010824</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>20010901</td>\n",
       "      <td>2001-09-01</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   datetime  year  month  yearID  monthID  monsoon  monsoonID  \\\n",
       "0    20010909 2001-09-09  2001      9       0        9      1.0        0.0   \n",
       "1    20010917 2001-09-17  2001      9       0        9      1.0        0.0   \n",
       "2    20010925 2001-09-25  2001      9       0        9      1.0        0.0   \n",
       "3    20011003 2001-10-03  2001     10       0       10      1.0        0.0   \n",
       "4    20011011 2001-10-11  2001     10       0       10      1.0        0.0   \n",
       "..        ...        ...   ...    ...     ...      ...      ...        ...   \n",
       "980  20010731 2001-07-31  2001      7       0        7      1.0        0.0   \n",
       "981  20010808 2001-08-08  2001      8       0        8      1.0        0.0   \n",
       "982  20010816 2001-08-16  2001      8       0        8      1.0        0.0   \n",
       "983  20010824 2001-08-24  2001      8       0        8      1.0        0.0   \n",
       "984  20010901 2001-09-01  2001      9       0        9      1.0        0.0   \n",
       "\n",
       "     idx  \n",
       "0      1  \n",
       "1      2  \n",
       "2      3  \n",
       "3      4  \n",
       "4      5  \n",
       "..   ...  \n",
       "980  981  \n",
       "981  982  \n",
       "982  983  \n",
       "983  984  \n",
       "984  985  \n",
       "\n",
       "[985 rows x 9 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8ea05703-7f28-481a-9b7b-0b349b166858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out to csv for record keeping\n",
    "outPath=rootPath/'pixelFIA/dates'\n",
    "outPath.mkdir(exist_ok=True)\n",
    "datesDF.to_csv(outPath/'datesMapping.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833ddc6-4eb4-468a-ac77-1f849f963b2a",
   "metadata": {},
   "source": [
    "### Aggregate by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbfa65-4f64-45f1-aece-7ed66f0cb383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexsaunders\\AppData\\Local\\Temp\\ipykernel_2192\\1276859065.py:19: RuntimeWarning: All-NaN slice encountered\n",
      "  rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n",
      "C:\\Users\\alexsaunders\\AppData\\Local\\Temp\\ipykernel_2192\\1276859065.py:19: RuntimeWarning: Mean of empty slice\n",
      "  rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n",
      "C:\\Users\\alexsaunders\\Anaconda3\\envs\\geo_rioxarray38_\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "C:\\Users\\alexsaunders\\Anaconda3\\envs\\geo_rioxarray38_\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1583: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by year - take the maximum, mean and median\n",
    "years = np.unique(datesDF.year)\n",
    "nyears = len(years)\n",
    "avgs = ['max','mean','median', '95pct']\n",
    "q=0.95\n",
    "navgs = len(avgs)\n",
    "rasterDataAvgAllDates=np.zeros([nyears, navgs, nrows*ncols])\n",
    "\n",
    "for y, year in enumerate(years):\n",
    "    print(year)\n",
    "    \n",
    "    # Get the indexes for the given filter\n",
    "    idxs = list(datesDF[datesDF.year==year].index)\n",
    "    \n",
    "    # Get the rasterData for those timesteps which are in the filter\n",
    "    rasterDataIdxs = rasterData2Dnan[:,idxs]\n",
    "    \n",
    "    # Get the average metrics from the selected timesteps\n",
    "    rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n",
    "    \n",
    "    rasterDataAvgAllDates[y,:,:] =  rasterDataAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbdc67-0470-4425-9eda-c82dd8e039e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe for writing out as csv\n",
    "outPath=rootPath/'pixelFIA/annual'\n",
    "outPath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce19a62-8f0c-48ab-9046-1d92db3883f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through max, mean, median, 95pct and for each , write out all years to a csv - \n",
    "for i in range(navgs):\n",
    "    rasterDataAvgDF = rasterDataAvgAllDates[:,i,:]\n",
    "    outName=avgs[i]+'.csv'\n",
    "    rasterDataAvgDF.to_csv(outPath/outName,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda62c28-ce6e-4e85-b9dc-494fdf00c4ff",
   "metadata": {},
   "source": [
    "### Aggregate by season, monsoon months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "73e96e90-dc93-4ffa-bb67-37b81febae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexsaunders\\AppData\\Local\\Temp\\ipykernel_2192\\1086616126.py:19: RuntimeWarning: All-NaN slice encountered\n",
      "  rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n",
      "C:\\Users\\alexsaunders\\AppData\\Local\\Temp\\ipykernel_2192\\1086616126.py:19: RuntimeWarning: Mean of empty slice\n",
      "  rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\r"
     ]
    }
   ],
   "source": [
    "# Aggregate by year - take the maximum, mean and median\n",
    "years = np.unique(datesDF.year)\n",
    "nyears = len(years)\n",
    "avgs = ['max','mean','median', '95pct']\n",
    "q=0.95\n",
    "navgs = len(avgs)\n",
    "rasterDataAvgAllDates=np.zeros([nyears, navgs, nrows*ncols])\n",
    "\n",
    "for y, year in enumerate(years):\n",
    "    print(year, end='\\r')\n",
    "    \n",
    "    # Get the indexes for the given filter\n",
    "    idxs = list(datesDF[(datesDF.year==year) & (datesDF.monsoon==1)].index)\n",
    "    \n",
    "    # Get the rasterData for those timesteps which are in the filter\n",
    "    rasterDataIdxs = rasterData2Dnan[:,idxs]\n",
    "    \n",
    "    # Get the average metrics from the selected timesteps\n",
    "    rasterDataAvg = np.array([np.nanmax(rasterDataIdxs, axis=1), np.nanmean(rasterDataIdxs, axis=1), np.nanmedian(rasterDataIdxs, axis=1), np.nanquantile(rasterDataIdxs, q, axis=1)])\n",
    "    \n",
    "    rasterDataAvgAllDates[y,:,:] =  rasterDataAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "287aedf8-c8fd-432b-84b7-55afa70bc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe for writing out as csv\n",
    "outPath=rootPath/'pixelFIA/monsoon'\n",
    "outPath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "796a95ab-78e9-495c-9c86-3fd169b20b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through max, mean, median, 95pct and for each , write out all years to a csv - format is cols = pixels locations, rows = years (in order from 2001-2022 inclusive)\n",
    "for i in range(navgs):\n",
    "    rasterDataAvgDF = pd.DataFrame(rasterDataAvgAllDates[:,i,:])\n",
    "    outName=avgs[i]+'.csv'\n",
    "    rasterDataAvgDF.to_csv(outPath/outName,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e58484fc-875c-4b68-ba82-de0511d69240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(outPath/outName, index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
